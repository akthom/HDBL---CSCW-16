\section{Discussion}

Like buildings, databases adapt and change over time in response to their users -- and those constraints and changes at the logical level, in turn, can impact ways and styles of work.  Here we discuss in further depth the implications of this co-shaping of work for CSCW, particularly as it affects work and information systems in the very long term. We identify a number of implications not just for CSCW research and design, but also for that of data curation and digital preservation systems, and argue that a CSCW perspective could greatly improve the quality of the latter. [come back to this]

\subsection{Schemas, software, and the co-construction of work}


In our cases, work with databases was co-constructed by people, data models, and software in several key ways: 
\begin{enumerate}
\item The kind and format of data that can be stored in a database are fundamentally shaped by not just the data model, but also the user’s ability to change that model. Where Codd may have intended that the logical schema be updated to accommodate new data, ad hoc work-arounds (putting data into notes or remarks fields, co-opting fields, or exporting the database to a flat file for curation) are often used when users cannot change the schema due to other constraints. These work-arounds may work reasonably well at the time of their initial implementation, but can have unexpected effects when databases need to be migrated either to ward off obsolescence or meet evolving community needs (as illustrated by the problems encountered by Specify users in migrating co-opted fields). 

\item Even when databases are initially well-normalized and built “up to code”, complex relationships between tables can eventually become a barrier to use – particularly if there is a mismatch between the original creator’s ability to manipulate the data model and the user’s or new custodian’s. In our cases, this barrier became most obvious during the “handover” phase, in which a new collections manager takes over custody of a database and must painstakingly reverse engineer its structure. 
\item That said, complex relationships can also facilitate use -- when they’re being managed by someone who is able to act as a true administrator of the database. For instance, the Decapod Systematics Database described above features a fairly complex relational structure designed to track changes, as well as make visible the reasons for those changes. Thanks to several well-implemented web forms, these relationships do not need to be understood by the users of the database – only by the administrator.
\item Databases learn their “vernacular” from their “neighbors” just as buildings do; in our cases, “neighbors” include colleagues within the same community of practice who share their data structures, and encourage one another to adopt similar designs for later integration. The NHM community’s move toward use of Specify and Arctos may also be viewed as a number of databases adopting a common style. 
\end{enumerate}

Finally, the broad adoption of Specify and Arctos by NHMs can be viewed as the result of their collections databases “demanding” more formal administrators. As we reviewed at the beginning of this paper, Codd’s relational model is rooted in an assumed division of labor between administrators and users: users do data entry and retrieval, and administrators manage the mappings between the physical, logical, and conceptual levels of the database. However, in our cases, users and administrators are often one in the same. Because both Specify and Arctos come with pre-designed, unalterable data schemas, their use essentially outsources some of that administrator role to the Specify and Arctos developers.  [come back to this]

While Specify and Arctos users are the administrators of their collections, and collections’ data, they are not the administrators of her database's underlying schema, per se: the Specify and Arctos developers are.  While the Specify database, in particular, is certainly "learning" from its user base in some important ways – making changes to schemas in response to feedback – the learning process is somewhat more delayed than it would be if local 




\subsection{Comparisons with related studies}
[this might need moving or deleting, depending on space]
\subsubsection{Voida et al}

Voida et al.'s study of coordinators of volunteers at various non-profit organizations \cite{voida2011homebrew} has interesting similarities and differences from our study of NHMs. They found considerable use of other software (especially personal office applications such Excel and Outlook) to record information that might be expected to be more appropriately stored in a database. We also found considerable Excel use but not Outlook. The difference may be accounted for by one of the main activities of the volunteer coordinators being to communicate with volunteers. 

By contrast, collections managers typically had much more database expertise and comfort, and yet at times they too used spreadsheets to store data. We believe this is an important point of comparison. It can be tempting to say that some people use spreadsheets to store data rather than a proper database because they don't know any better or lack the skills to develop and maintain a database. This was not the case for our collections managers and so we must seek other reasons for their use (at times) of spreadsheets.

Clearly for processing certain kinds of result, spreadsheets are an entirely appropriate tool. It is not surprising that scientists would import data from a database into a spreadsheet in order to run certain calculations. But spreadsheets get used for many other purposes – just as email systems do \cite{bellotti2005quality}. Reasons include familiarity and facility. If you use spreadsheets a lot, then through inertia it is just there, already running on you computer. Also through regular use you learn how to be able to do many things with them, you are comfortable doing them, and you may also be more comfortable innovating and tinkering with them.  Consequently spreadsheets may be a convenient location for both mundane and more experimental data use. These include data management activities such as data cleaning and consistency checking.  Other reasons include the relative visibility (and comforting familiarity) of the tabular representation and the ease of checking the consequences of actions \cite{nardi1991twinkling}. As a conceptually comfortable data cache (or staging zone), there can be relatively few concerns about spreadsheet use. However, as spreadsheets start to become slightly longer term repositories of data, or serve as a resource parallel to but unsynchronized with the database but  we might worry more. A buildings analogy might be a room that 'temporarily' becomes an additional storage space, but then never reverts to its main use.

A telling perspective from the NPO study is that “information management is not the real work of volunteer coordination; it is overhead.” This naturally affects the allocation of effort, resources and indeed enthusiasm. For collections managers, information management is far more central. But if we see similarities in activity between these different settings despite the contextual differences it requires us to seek better explanations of why people use the technologies the way that they do. From the NPO study: “In lieu of a system that can do everything, volunteer coordinators continually reconfigure their homebrew databases—swapping one system for another and hoping the new set of systems will help reduce overhead in managing information.”  and: “We heard over and over again that volunteer coordinators were in the process of migrating their data from one application to another.” These migrations seem more frequent and perhaps more ad hoc than in our natural history museum settings, but that migrations are a recurrent issue in both contexts is important to bear in mind, and rises the question of how common migrations are in yet other contexts. If you are aware that your database is likely to be migrated a number of times in its life, this may (or perhaps should) have an impact in how you design and maintain it. The act of migration is often problematic. In the case of the NPOs: "Existing data either has to be ported — frequently necessitating manual re-entry of the data or selective copying and pasting — or abandoned. New systems rarely, if ever, encompass the same set of features or afford the same degree of flexibility as previous systems. Changes in the information managed by one application influence information management in others.” Despite better database skills and a closer alignment of database management with the 'real work' of the organization, certain similarities of re-entry and particularly of checking occurred in museums.

One challenge is the evolving purpose and use of a database. How can a database achieve, in Ribes’ terms, ‘technoscientific flexibility’? \cite{ribes2014kernel} . That requires the database to be able to respond to changing user needs and to the opportunities of new technologies. Migration plays a role in both of these.

Another important piece of work that we want to compare our findings with involves a collaborative project between database researchers and biologists   \cite{jagadish2007making}. This uncovered a number of database usability issues that can arise when domain experts (but who are not necessarily database experts) have to deal with the development and use of databases as part of their work. In general terms they note: “When we speak of usability, we mean much more than just the user interface, which is only a part of the usability equation. A more fundamental concern is that of the underlying architecture.” We too want to uncover the way that the underlying architecture affects use, and in particular changing use over time. As database expects they also note an irony in normalization. Codd proposed normalization as a way to protect end users from the underlying structure of the data, and make that data more robust over time and incremental changes. Jagadish et al. note that “We break apart information during the database design phase such that everything is normalized—space efficient and updatable. However, the users will have to stitch the information back together to answer most of the real queries. The fundamental issue is that joins destroy the connections between information pertaining to the same real world entities and are nonintuitive to most normal users." As a result, databases may fail to be normalized for reasons of usability - or even deliberately de-normalized. [any examples, riffs on these ideas from our data?] Finally, spreadsheets as data containers appear yet again - but with a usability perspective on why: “While joins across multiple normalized tables may be difficult, people are certainly used to seeing data represented in simple two-dimensional tables. The popularity of the Excel spreadsheet as a data model speaks to this. For situations where data can be represented conveniently as a table, a tabular model is certainly appropriate."

\subsubsection{Bietz and Lee}

They talk about participants idealizing a "Perfect Database" - ours do too, to an extent, but it's more collections based.

\subsection{Temporally distributed cooperative work}

A consideration of database use, change and maintenance over long periods of time has numerous connections to CSCW. Handovers and handoffs are a recurrent theme in CSCW in a variety of settings ranging from medicine to paper mills (e.g. \cite{sarcevic2009information};  \cite{auramaki1996paperwork}). In the case of NHM databases a critical issue for a database to be successfully long-lived is the handover from one database manager to another. These occur at much longer time periods than the shift-level handover (from years to decades) and so are likely to a far less practiced or routinized skill. Ideally a handover involves a period of time for face to face meetings, even an apprenticing into the role for the newcomer. But it can also be more indirect, involving the use of documents and a degree of reverse engineering. In problematic cases it is a kind of CSCW where there is far less collaboration than is desired, and certain computational resources compensate for the lack of collaboration. 

Given the long term use of the database, there may even be work to hand over information to your future self – sending yourself messages to be read many years later that will facilitate the maintenance, interpretation or migration of the data. Such issues are not unique to databases by any means. They are strongly analogous to work in the ongoing documenting (or lack thereof) and maintenance of long lived programs – a topic studied by software engineering for decades. It is rather odd that equal attention has not been paid to the very similar but not identical challenges of maintaining databases as opposed to programs over many years. Both handovers and migrations have something of a rhythmic aspect, but they are are more like the bursty rhythms of Jackson et al. \cite{jackson2011collaborative}

\subsubsection{Infrastructure, collaboration and levels of visibility}

As Star reminds us, infrastructure becomes visible upon breakdown. What we would add is that breakdown is often when collaboration also increases, - or maybe the infrastructure-enabling collaboration suddenly becomes more visible to some of the people involved. 

[I don't think that a lot of what was in this section bears with the data - and even if it does, this section may need to be entirely scrapped - because we don't foreshadow this discussion.  OR - need to be clearer that we're talking about either:
a) unseen collaboration between present users and past users, or 
b) cooperative work btwn users and designers of databases like Specify.

I'd also written in my field exam on steps people take to deliberately bring infrastructure into view - that might fit but I am not sure]

\subsubsection{The the mundane, but meaningful}

Our focus is on long-lived scientific databases in natural history museums where new entries are added, and certain entries and values may be revised over time. The databases are used by scientists and are expected to continue to be used for years, decades and centuries – just as their precursors have. These are not particularly large databases - they would not count as "big data" - nor do they contain rapidly changing transactional data. They are not databases whose contents are now fixed and are not currently being used, but need to be archived in case they are  needed in the future, as explored by Olson \cite{olson2010database}. This last case of archiving is less like one of Brand’s learning buildings and more like an historic monument with a restrictive preservation order applied to it.

Although not large from the perspective of giant astronomy projects or corporate examples, they are  significant and are not trivially small. Many can reside in current powerful laptop computers, even it it would be better to have them on servers. They are unlikely to receive the attention of database researchers (Jagadish is a commendable exception) who are likely to be working on the challenges of much greater scale, levels of use and rates of change. But improving their usability for those who create, update and use them, and knowing the degree of difference (if any) between users and maintainers is important. In particular the collaborations around their use and particularly around their maintenance over decades (and, we can hop, centuries) is an important challenge where insights from CSCW can play a vital role.

We suspect that there are similar database uses and needs outside Natural History Museums, and not just in other scientific settings. Inspired by Voida et al. we think there may be  many other domains ( where people “need to manage information too complex for paper or personal office applications, but who cannot confront the overhead of using enterprise “solutions.” We would go further and note that with increasingly powerful machines there is an opportunity and even an expectation that people will be managing ‘moderate sized’ datasets. These are typically too large or unwieldy for paper or personal office applications, but look like very modest datasets from the perspectives of many systems administrators or especially database researchers. Our laptops and PCs may run them well, but we may not. The tools, features and interfaces needed for moderate databases are different from those for large ones. As Jagadish et al. remind us, too much power and many choices can be a significant disadvantage in moderate database usability.

\subsubsection{Design recommendations/future work?}

\textbf{design: }
- how do we design relational databases that support not just information storage and retrieval, but rather,  curatorial work and collections management? e.g. things like georeferencing; taxonomic referencing; clustering and batch editing as in Open Refine. (or: how can we merge open refine with specify?)
- Like Buneman, we see a definite need to support better provenance tracking in curated databases \cite{Buneman_2006}; however, we would argue that the actions tracked or bundled at at a higher level than "insert, delete, copy, and paste" actions -- while the core of data curatorial work may appear to a computer like a sequence of insertions, deletions and copies
- additionally: need to support visual rearrangement and browsing of tables and tuples; this might have SQL at its core but needs to be more user friendly. Bulk of HCI/UX studies have been about query construction - less has been written about user-friendliness of database GUIs, particularly from a curatorial perspective (e.g. someone doing quality assessment, editing, as opposed to just data entry, or just information retrieval
- need support for review of students'/volunteers' data entry  -- right now there's no great way to handle this.

\textbf{future work:}
- logical modeling as a design problem for CSCW
- in what ways do people come to know an information system? we need to study not just long lived databases but also people who work with databases for a longer period of time - people who gain almost tactile knowledge of information systems based on consistent use (as opposed to studies of how naive users use a database once).
- We'd like to study comprable organizations with relational databases.