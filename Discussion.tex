\section{Discussion}

Like buildings, databases adapt and change over time in response to their users -- and those constraints and changes at the logical level, in turn, can impact ways and styles of work. Here we discuss in further depth the implications of this mutual constitution, particularly as it affects work in the very long term. We place our work in the context of other related studies in CSCW; briefly review our typology of databases; and identify a number of implications for CSCW research and design. We particularly argue that CSCW should consider information modeling as a design challenge.

\subsection {Ties with and contributions to other work in CSCW}
\subsubsection{Database use beyond the museum}

Our study should be placed in context of others by Jagadish et al \cite{jagadish2007making} and Voida, Harmon & Al Ani \cite{voida2011homebrew} which similarly study workplaces in which people "need to manage information too complex for paper or personal office applications, but who cannot confront the overhead of using enterprise 'solutions'" (ibid). In a collaborative project with biologists, Jagadish et al. discovered a number of database usability issues that can arise when domain experts who are not necessarily database experts have to deal with the development and use of databases as part of their work. Like us, they also note a problem inherent in the relational model: Codd proposed normalization as a way to protect end users from the underlying structure of the data, and make that data more robust over time and incremental changes. Jagadish et al. explain, "We break apart information during the database design phase such that everything is normalized -- space efficient and updatable. However, the users will have to stitch the information back together to answer most of the real queries. The fundamental issue is that joins destroy the connections between information pertaining to the same real world entities and are nonintuitive to most normal users."  They find, as we do, that databases may fail to be normalized or deliberately denormalized for reasons of usability.

Voida, Harmon & Al Ani present a study was of people who coordinate volunteers at various non-profit organizations \cite{voida2011homebrew}. They also found considerable use of Excel to store data, and ascribe the use of Excel to a mixture of convenience, flexibility and familiarity. In our study, collections managers typically had much more database expertise than Voida et al. noted for the non-profit coordinators, yet still rely on Excel. Thus, lack of database expertise is not the only reason for using non-database resources to store data. Where others have noted the weight of the "psychological heritage of print" when wayfinding in databases \cite{Kerr_1990}, here we might note the psychological heritage of the spreadsheet for data entry and manipulation.

Voida, Harmon & Al Ani also note, "we heard over and over again that volunteer coordinators were in the process of migrating their data from one application to another." This raises the question of how common migrations are in yet other contexts, and how we might begin to design and curate databases for migration. How can a database achieve, in Ribes' terms, 'technoscientific flexibility' \cite{ribes2014kernel}?

\subsubsection{Very temporally dispersed cooperative work}

The CSCW community has long studied contexts of great spatial or geographic dispersion; here we contribute to recent work exploring how CSCW is done across dispersed \textit{temporal} distances (e.g. \cite{Jackson_2011, Lindley_2015}). However, where several studies have explored how time matters in fast-paced, time-sensitive environments such as nursing \cite{sarcevic2009information, Reddy_2006} and paper mills \cite{auramaki1996paperwork}, ours contributes to an understanding of how time matters in extremely long-lived, if slower-paced environment: memory institutions. Museums must, by dint of their preservation mandate, take an extremely long view of work; as Bowker has noted, the process of databasing the world is a fundamentally a long-term one, and one that makes most of its progress through slow, steady curatorial progress \cite{Bowker_2000}. However, this work isn't without interruption. Collections databases have longer tenures at museums than their managers, and longer lifespans than the software used to store them; thus transitions between people and technology alike can be disruptive. However, for NHMs, the most critical point of information transfer is not at a shift change, as it is in medical work, or even at the point at which one collection manager replaces another. Rather, it's at the point of migration from one system to another.

A long-view of cooperative work shows us that there is a need to design relational databases that support not just information storage and retrieval, but rather, data curation as well: tools that allow data managers to assess changes to data and schemas that accrue over time, and make changes to the database's structure or contents as needed. Additionally, like \cite{Buneman_2006} and \cite{jagadish2007making}, we see a definite need to support better provenance tracking in curated databases. However, our cases contribute to an understanding what provenance information is needed at a higher level than even the "coarse-grained" provenance they describe. Not only must users know what changes were made over time, but they must understand what social and technical constraints or concerns motivated changes. Further, our cases echo Voida, Harmon & Al Ani's finding that there's a need to not just track provenance within one system, but between data systems (e.g. between Excel and databases) \cite{voida2011homebrew}.

\subsubsection{Towards a typology of databases}

This study has looked at what might be classified medium-sized databases: databases that certainly don't fall under the umbrella of "big data" behemoths that requires petabytes of storage, yet still are complex or large enough to require some sort of structure beyond a flat file spreadsheet. We have further classified these databases according to the following types:

\begin{itemize}
\item Collections management databases: these are used to support the management of a physical specimen collection by organizing and preserving data about the specimens. They have typically been migrated from paper formats and are meant to last for the forseeable future. These are used for information storage and retrieval and data curation.
\item Research databases: these are created specifically to support scientific projects and answer specific research questions. They are often integrative in nature, drawing from many different collections and sources of data; in biology these variously function as models of organisms\cite{Hine_2006}, models of the world \cite{Bowker_2000}, or in the case of taxonomic (species description) databases, models of the state of knowledge. Research databases are used for information storage and retrieval, data curation, and analysis.
\item Transactional databases: these are used for processing and tracking transactions such as loans, purchases and accessions over time. While they are used for information storage and retrieval, they are not used for curation.
\end{itemize}

Each of these types of databases has distinct roles and uses within a museum, and thus, distinct design needs and considerations. However, much of database research -- as well as tutorials for database design -- focus on the creation and management of what we've called transactional databases: those concerned without a curatorial focus. 

We suspect our typology could be applied to and helpfully expanded through study of other domains. The resulting typology could lead to the identification of database problems common to types -- as well as to the creation of more tailored tools and resources.

\subsection{Schemas, software, people, and the mutual constitution of database work}

One of the motivating propositions behind this research is that database work is sociotechnical -- databases shape people just as much as people shape databases -- and that by better understanding the specific nature of this mutual constitution between people and databases, we can identify ways to make database work better. In our cases, work with databases is mutually constituted by people, data models, and software in several key ways: 
\begin{enumerate}
\item The kind and format of data that can be stored in a database are fundamentally shaped by not just the data model, but also the user’s ability to change that model. Where Codd may have intended that the logical schema be amended to accommodate new data, ad hoc workarounds (putting data into notes or remarks fields, co-opting fields, or exporting the database to a flat file for curation) are often used when users cannot change the schema due to other constraints (e.g. they don't have the necessary administrative permissions to change the schema, or they simply don't know how). These workarounds may work reasonably well at the time of their initial implementation, but can have unexpected effects when databases need to be migrated either to ward off obsolescence or meet evolving community needs (as illustrated by the problems encountered by Specify users in migrating co-opted fields). 
\item Even when databases are initially well-normalized and built "up to code", complex relationships between tables can eventually become a barrier to use \cite{jagadish2007making}, – particularly if there is a mismatch between the original creator’s ability to manipulate the data model and the user’s or new custodian's. In our cases, this barrier became most obvious during the "handover" phase, in which a new collections manager takes over custody of a database and must painstakingly reverse engineer its structure. 
\item That said, complex relationships can also facilitate use -- when they are being managed by someone who is able to act as a true administrator of the database. For instance, the Decapod Systematics Database described above features a fairly complex relational structure designed to track changes, as well as make visible the reasons for those changes. Thanks to several well-implemented web forms, these relationships do not need to be understood by the users of the database – only by the administrator -- and the functionality they afford are fundamental to what makes the database a valuable community resource.
\item Databases learn their “vernacular” from their “neighbors” just as buildings do; in our cases, “neighbors” include colleagues within the same research community who encourage one another to adopt similar designs for later integration, or simply share data schemas to save each other some design work. Our case’s move toward use of Specify and Arctos may also be viewed as a number of databases adopting a common style. 
\item Databases create a demand for administrators. As we reviewed at the beginning of this paper, Codd’s relational model is rooted in an assumed division of labor between administrators and users: users do data entry and retrieval, and administrators manage the mappings between the physical, logical, and conceptual levels of the database. However, in our cases, users and administrators are often one and the same. Though many of the databases observed in this study started out as custom-made systems created by someone straddling the user/administrator divide, their migration to systems like Specify or Arctos reestablishes users and administrators as separate roles. Thus, Specify and Arctos aren't "just" pieces of software -- they do very little that a system like MySQL or Access can't. Rather, they are sociotechnical bundles of software and work arrangements.
\end{enumerate}

These findings, first and foremost, point to the importance of teaching database administrators in a range of institutional settings the fundamentals and importance of information modeling. However, for a CSCW audience, these findings show the importance of treating information modeling as an on-going design concern, as well as the need to develop tools that can assist users with the management and implementation of data models over time. Further, CSCW-concerned database designers should take note of the frequency at which, and reasons why database users must iterate their data through flat-file programs for data curation and normalization tasks. The existing ways in which flat files are used for data cleaning clearly point to functionalities that could be added to database software to support not just information storage and retrieval, but data curation as well.  For instance, two of the databases in this study were curated and migrated with the help of Open Refine\footnote{http://openrefine.org/}, a (now) open source data cleaning "power tool" that allows users to perform sophisticated data cleaning operations in a simple, Excel-like interface. Open Refine functions include everything from condensing consecutive white space in strings, to clustering text according to different algorithms for batch editing and normalization, to filtering and parsing data with regular expressions. In short, it's the exact kind of tool that should be directly integrated with database programs. We also point to methodologies such as OntoClean, a formal methodology for analyzing information models and their consequences \cite{Guarino_2004}. Database software that puts these methodologies into practice could be an invaluable contribution to data curation.
